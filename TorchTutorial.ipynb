{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a minimal tutorial for our lab. We only include basic functions, and functions that we will use in our lab. If you are interested in more operations of tensors and pytorch's design concept, see their [official tutorial](https://pytorch.org/tutorials/beginner/introyt.html)"
      ],
      "metadata": {
        "id": "U550SLeVHSr0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "yZ-jAD9K96hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor\n",
        "A tensor is a basic computing object/unit in pytorch.   \n",
        "It can be a scalar, a vector, or a matrix."
      ],
      "metadata": {
        "id": "wGFCkGxcxK0l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Constructing a tensor"
      ],
      "metadata": {
        "id": "LYO5bBUN-z5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a tensor with random number between 0 and 1\n",
        "tensor_a = torch.rand(2,5) # this will create a tensor/matrix with shape 2*5\n",
        "tensor_b = torch.rand(5,2)\n",
        "\n",
        "print(tensor_a, tensor_b)\n",
        "print(tensor_a.shape, tensor_b.shape) #.shape tell you the shape of the tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C63BjRSr-18y",
        "outputId": "954010e6-e1f9-44da-8ec2-0ce709effc1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8183, 0.5711, 0.0145, 0.7580, 0.4126],\n",
            "        [0.2131, 0.8202, 0.0451, 0.2402, 0.0909]]) tensor([[0.2436, 0.9331],\n",
            "        [0.7286, 0.4861],\n",
            "        [0.5188, 0.5906],\n",
            "        [0.2985, 0.6062],\n",
            "        [0.8484, 0.2746]])\n",
            "torch.Size([2, 5]) torch.Size([5, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a tensor with all zeros\n",
        "tensor_a = torch.zeros(2,5)\n",
        "# construct a tensor with all ones\n",
        "tensor_b = torch.ones(2,5)\n",
        "\n",
        "tensor_a, tensor_b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e1XHJYkxg5N",
        "outputId": "b1eb814f-4178-4a76-cdef-e4f3ee802e18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]),\n",
              " tensor([[1., 1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1., 1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a tensor from list\n",
        "numbert_list = [[1, 2, 3],\n",
        "                [4, 5, 6]]\n",
        "tensor_a = torch.tensor(numbert_list)\n",
        "\n",
        "tensor_a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQYVCxoXx6ho",
        "outputId": "e9ebd25f-3742-480e-b5a1-133d32195e89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a tensor can have different data types, you can manually cast it to different data types with \".to\"\n",
        "# the default data type is float32\n",
        "tensor_a = torch.rand(2,5)\n",
        "print(tensor_a)\n",
        "tensor_a = tensor_a.to(torch.float64)\n",
        "print(tensor_a)\n",
        "tensor_a = tensor_a.to(torch.int8)\n",
        "print(tensor_a)\n",
        "# you can also use \".to\" to move tensor to another device ('cuda', 'cpu')\n",
        "tensor_a = tensor_a.to('cpu') # modify this to 'cuda' if gpu is available\n",
        "print(tensor_a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XolcIp1nyPfQ",
        "outputId": "070417ae-8b1f-4091-f258-8d97509e8c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5005, 0.5656, 0.2767, 0.4751, 0.2111],\n",
            "        [0.4641, 0.1607, 0.0685, 0.0403, 0.5200]])\n",
            "tensor([[0.5005, 0.5656, 0.2767, 0.4751, 0.2111],\n",
            "        [0.4641, 0.1607, 0.0685, 0.0403, 0.5200]], dtype=torch.float64)\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]], dtype=torch.int8)\n",
            "tensor([[0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0]], dtype=torch.int8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# you can also get scalar/list from a tensor\n",
        "tensor_a = torch.rand(2,5)\n",
        "print(tensor_a)\n",
        "# get scalar with \".item()\"\n",
        "print(tensor_a[0, 0].item())\n",
        "# get list with \".tolist()\"\n",
        "print(tensor_a[0].tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjcEm3HPzHoO",
        "outputId": "4d768170-eacb-4b19-d678-0be9dfe53a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0488, 0.3261, 0.5420, 0.6538, 0.3788],\n",
            "        [0.3946, 0.3052, 0.2000, 0.6714, 0.6928]])\n",
            "0.048793256282806396\n",
            "[0.048793256282806396, 0.3260539174079895, 0.5420272350311279, 0.6538013815879822, 0.378842830657959]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct a tensor with given shape and filled with a given number\n",
        "full_matrix = torch.full((2,3),42) # number: 42, shape: 5*5\n",
        "\n",
        "full_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbHx70MD1bY-",
        "outputId": "df5c5ee4-e7a0-4bf4-b7c2-c3da8e3aa9d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[42, 42, 42],\n",
              "        [42, 42, 42]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix multiplication\n",
        "\n",
        "[torch.matmul](https://pytorch.org/docs/stable/generated/torch.matmul.html)"
      ],
      "metadata": {
        "id": "D0-X5rrU9XRv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTVpfVlC9Oza",
        "outputId": "08a16b01-0dfe-4f80-ddc3-a16744e03220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 4,  5],\n",
            "        [11, 13]])\n"
          ]
        }
      ],
      "source": [
        "a = [[1, 1],\n",
        "     [2, 3]]\n",
        "b = [[1, 2],\n",
        "     [3, 3]]\n",
        "tensor_a = torch.tensor(a)\n",
        "tensor_b = torch.tensor(b)\n",
        "print(torch.matmul(tensor_a,tensor_b))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outer product\n",
        "compute outer product between two vectors\n",
        "[torch.outer](https://pytorch.org/docs/stable/generated/torch.outer.html)"
      ],
      "metadata": {
        "id": "HK94wgZDLG7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor_c = torch.arange(1,5)\n",
        "tensor_d = torch.arange(3,7)\n",
        "\n",
        "out_product = torch.outer(tensor_c,tensor_d)\n",
        "\n",
        "tensor_c, tensor_d, out_product"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRxs7p90LJZ5",
        "outputId": "09114200-978c-427f-9f91-89d241e49b8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3, 4]),\n",
              " tensor([3, 4, 5, 6]),\n",
              " tensor([[ 3,  4,  5,  6],\n",
              "         [ 6,  8, 10, 12],\n",
              "         [ 9, 12, 15, 18],\n",
              "         [12, 16, 20, 24]]))"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Filter out the upper triangle of one matrix\n",
        "\n",
        "[torch.triu](https://pytorch.org/docs/stable/generated/torch.triu.html)"
      ],
      "metadata": {
        "id": "UBGzmTsFDEYV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_matrix = torch.rand(5,5)\n",
        "print(original_matrix)\n",
        "\n",
        "upper_triangle = torch.triu(original_matrix)\n",
        "print(upper_triangle)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bfr6Lx4CWeC",
        "outputId": "dde9a42b-452c-4b68-9334-25b4bd2c1d0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3469, 0.5627, 0.8815, 0.6117, 0.9736],\n",
            "        [0.1828, 0.8382, 0.3507, 0.3997, 0.1586],\n",
            "        [0.9514, 0.8613, 0.2656, 0.3286, 0.6707],\n",
            "        [0.6839, 0.0701, 0.4457, 0.1063, 0.4885],\n",
            "        [0.9282, 0.6690, 0.6848, 0.8794, 0.5329]])\n",
            "tensor([[0.3469, 0.5627, 0.8815, 0.6117, 0.9736],\n",
            "        [0.0000, 0.8382, 0.3507, 0.3997, 0.1586],\n",
            "        [0.0000, 0.0000, 0.2656, 0.3286, 0.6707],\n",
            "        [0.0000, 0.0000, 0.0000, 0.1063, 0.4885],\n",
            "        [0.0000, 0.0000, 0.0000, 0.0000, 0.5329]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Softmax"
      ],
      "metadata": {
        "id": "8VOeZig3D8aC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Softmax is calculated by\n",
        "\n",
        "![](https://drive.google.com/uc?id=1qEJAgU3s4QLN-ELv5PjlE0lzlA7wT9uU)\n",
        "\n",
        "This returns the value proportioned to the sum of value along a given dimension.\n",
        "\n",
        "Simply put, the process is given as followed:\n",
        "\n",
        "1. Take exponential for each element in the matrix.\n",
        "2. Sum the exponential value along the given dimension.\n",
        "3. Divide the first step by the second step with their corresponding dimension."
      ],
      "metadata": {
        "id": "72XBl4zDMVZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's demonstrate how we derive softmax manually\n",
        "# Here, we calculate sofatmax in the first row\n",
        "Row = upper_triangle[0]\n",
        "Sum_of_this_row = torch.sum(torch.exp(Row))\n",
        "print(\"Sum of exponentials of the first row: \", Sum_of_this_row)\n",
        "for i in range(upper_triangle.size(1)):\n",
        "  print(f\"original value: {Row[i]}\")\n",
        "  print(f\"exponential value: {torch.exp(Row[i])}\")\n",
        "  print(f\"elements divided by sum of exponentials: {torch.exp(Row[i])/Sum_of_this_row}\")\n",
        "\n",
        "\n",
        "## Softmax\n",
        "softmax_1 = torch.nn.functional.softmax(upper_triangle,dim=1)\n",
        "print(softmax_1) # you can see the first row is the same as we do manually"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aGe_JUfDZTu",
        "outputId": "a816a520-4730-4d2c-c259-5e2566137216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max values of upper_triangle in the 0 dimension:  tensor([0.9736, 0.8382, 0.6707, 0.4885, 0.5329]) \n",
            "\n",
            "\n",
            "Sum of exponentials of the first row:  tensor(10.0754)\n",
            "original value: 0.346870481967926\n",
            "exponential value: 1.4146335124969482\n",
            "elements divided by sum of exponentials: 0.1404043287038803\n",
            "original value: 0.5627419352531433\n",
            "exponential value: 1.755479335784912\n",
            "elements divided by sum of exponentials: 0.17423374950885773\n",
            "original value: 0.8814697861671448\n",
            "exponential value: 2.4144458770751953\n",
            "elements divided by sum of exponentials: 0.239637091755867\n",
            "original value: 0.6116546392440796\n",
            "exponential value: 1.8434791564941406\n",
            "elements divided by sum of exponentials: 0.18296785652637482\n",
            "original value: 0.9735735058784485\n",
            "exponential value: 2.647387981414795\n",
            "elements divided by sum of exponentials: 0.26275691390037537\n",
            "tensor([[0.1404, 0.1742, 0.2396, 0.1830, 0.2628],\n",
            "        [0.1352, 0.3126, 0.1920, 0.2017, 0.1585],\n",
            "        [0.1504, 0.1504, 0.1962, 0.2089, 0.2941],\n",
            "        [0.1742, 0.1742, 0.1742, 0.1937, 0.2838],\n",
            "        [0.1753, 0.1753, 0.1753, 0.1753, 0.2987]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax over columns instead of rows\n",
        "softmax_2 = torch.nn.functional.softmax(upper_triangle,dim=0)\n",
        "print(softmax_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5AfWrJgEgL1",
        "outputId": "7bfc5981-16f0-40e9-9ed4-06d9a9fb4c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2613, 0.2484, 0.3382, 0.2697, 0.2906],\n",
            "        [0.1847, 0.3271, 0.1989, 0.2182, 0.1287],\n",
            "        [0.1847, 0.1415, 0.1827, 0.2032, 0.2147],\n",
            "        [0.1847, 0.1415, 0.1401, 0.1627, 0.1789],\n",
            "        [0.1847, 0.1415, 0.1401, 0.1463, 0.1871]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Use this helper function to inspect what internally a softmax do.\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "def manual_softmax_dim0(x):\n",
        "    # Step 1: Compute the exponential of each element\n",
        "    exp_x = torch.exp(x)\n",
        "\n",
        "    # Step 2: Compute the sum of exponentials along dimension 0\n",
        "    sum_exp_x = torch.sum(exp_x, dim=0, keepdim=True)\n",
        "\n",
        "    # Step 3: Divide each exponential by the sum\n",
        "    softmax_x = exp_x / sum_exp_x\n",
        "\n",
        "    return softmax_x\n",
        "\n",
        "# Calculate softmax manually\n",
        "# manual_result = manual_softmax_dim0(upper_triangle)\n",
        "\n",
        "# # Calculate softmax using PyTorch's built-in function\n",
        "# torch_result = F.softmax(upper_triangle, dim=0)\n",
        "\n",
        "# print(\"Manual Softmax result:\")\n",
        "# print(manual_result)\n",
        "# print(\"\\nPyTorch Softmax result:\")\n",
        "# print(torch_result)\n",
        "\n",
        "# # Verify that the results are the same\n",
        "# print(\"\\nAre the results equal?\", torch.allclose(manual_result, torch_result))"
      ],
      "metadata": {
        "id": "vUotzKYxG8Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reshape tensor\n",
        "\n",
        "[torch.view](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html)\n",
        "\n",
        "or\n",
        "\n",
        "[torch.reshape](https://pytorch.org/docs/stable/generated/torch.reshape.html)"
      ],
      "metadata": {
        "id": "4EET3dx8MY4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These 2 functions produces the same result. torch.view performs quicker as it does not allocate new memory; torch.reshape runs slightly slower because it will allocate new memories if needed.\n",
        "\n",
        "For details, please refer to [this blog](https://myscale.com/blog/torch-reshape-vs-torch-view-pytorch/)\n",
        "\n",
        "Pratically, torch.reshape is recommanded as it can handle more cases. We guaranteed that all tensors are contiguous in our lab so we will use torch.view to decrease computation time."
      ],
      "metadata": {
        "id": "FBjVqXOYNQ4a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "before_reshaped = torch.randn((2,5))\n",
        "print(before_reshaped)\n",
        "\n",
        "after_reshaped = before_reshaped.reshape(5,2)\n",
        "after_viewed = before_reshaped.view(5,2)\n",
        "\n",
        "print(after_reshaped)\n",
        "print(after_viewed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzg5e7DaOk6l",
        "outputId": "61e3c77e-b230-4c30-c8ea-48f9bd101bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3369,  0.9678, -0.8020, -0.4791,  1.1977],\n",
            "        [ 0.5820, -1.3635, -0.4105, -1.2536,  0.4773]])\n",
            "tensor([[ 0.3369,  0.9678],\n",
            "        [-0.8020, -0.4791],\n",
            "        [ 1.1977,  0.5820],\n",
            "        [-1.3635, -0.4105],\n",
            "        [-1.2536,  0.4773]])\n",
            "tensor([[ 0.3369,  0.9678],\n",
            "        [-0.8020, -0.4791],\n",
            "        [ 1.1977,  0.5820],\n",
            "        [-1.3635, -0.4105],\n",
            "        [-1.2536,  0.4773]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the index of max value\n",
        "\n",
        "[torch.argmax](https://pytorch.org/docs/stable/generated/torch.argmax.html)"
      ],
      "metadata": {
        "id": "SENMd6owO-Fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Argument max returns the \"index\" of the max value, in contrast of max, which directly returns the max value.\n",
        "\n",
        "(This can also be achieved my selecting indices of torch.max, but will be slightly slower.)"
      ],
      "metadata": {
        "id": "XHdxa7MUPOFH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix = torch.randn(2,3)\n",
        "print(matrix)\n",
        "\n",
        "max_value=torch.max(matrix,dim=1).values\n",
        "max_index=torch.argmax(matrix,dim=1)\n",
        "print(max_value)\n",
        "print(max_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nVl09yvPMxM",
        "outputId": "e0e893b4-d7ee-4470-ad7e-0011c275a20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2352, -0.6111,  1.6632],\n",
            "        [-0.0459, -0.9726, -0.4152]])\n",
            "tensor([ 1.6632, -0.0459])\n",
            "tensor([2, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EPD1psl9PkfL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}